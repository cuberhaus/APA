{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Primera lista - Problema GRUPAL 1\n",
        "\n",
        "Componentes del grupo:\n",
        "\n",
        "*   Pol Casacuberta Gil\n",
        "*   Joaquin Faraone Prieto\n",
        "*   Agnes Felip i Díaz \n",
        "*   Marta Granero i Martí\n",
        "\n",
        "## Dos mejor que una\n",
        "\n",
        "### Consideremos un experimento en el que medimos una determinada variable aleatoria $X$, que sigue una distribución Gaussiana univariante $(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2}))$. Tomamos n medidas independientes de $X$ y obtenemos una muestra aleatoria $\\{x_{1}, \\dots, x_{n}\\}$ donde cada $x_{i}$ es una realización de $X$, para $i = 1, \\dots, n$. Resolved los siguentes apartados, ilustrando los resultados de la manera que os parezca más adecuada.\n",
        "\n",
        "\n",
        "#### a) Escribid la función de densidad de probabilidad para una $x_{i}$ cualquiera y construid la función log-verosimilitud(negativa) de la muestra.\n",
        "\n",
        "La expresion matemática que representa la función de densidad de una distribución normal para una $x_{i}$ es la siguiente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{N}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Una vez dada la expresión de la función de densidad de la distribución normal para una $x_{i}$, nos piden construir la función de la log-verosimilitud negativa de la muestra.\n",
        "\n",
        "Esta función de la log-verosimilitud($\\mathcal{L}$) que vamos a construir, nos va a permitir encontrar los mejores parametros del modelo que se ajusten a los datos. O lo que es lo mismo, maximizaremos $\\mathcal{L(\\theta)}$ con respecto a los parámetros, $\\theta$. \n",
        "\n",
        "Lo expresaremos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; p(\\textbf X | \\theta) \n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si especificamos para nuestro caso, dónde p, sigue una distribución normal, tenemos:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\theta)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Notemos pues que: $\\mathcal{L(\\theta)} = p(\\textbf X | \\theta) = \\mathcal{N}(\\textbf X | \\theta)$\n",
        "\n",
        "Como bien sabemos los parámetros para una distribución gaussiana, son $\\mu$ y $\\sigma^{2}$. Entonces para una MLE de un modelo gaussiano, solo hará falta encontrar buenas estimaciones de ambos parámetros usando derivadas parciales. \n",
        "\n",
        "Los parámetros $\\theta$ son: $\\mu, \\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\mu, \\sigma^{2})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora sí, procedamos a construir la función:\n",
        "\n",
        "Como tratamos con n muestras, las quales son (iid), los parámetros a estimar deberan tener en cuenta todo el conjunto de datos, por lo tanto sumaremos la log-verosimilitud para cada muestra de datos $i$ que tenemos. Lo expresamos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "log (\\mathcal{N}(\\textbf X | \\theta)) = \\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2}))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora sustituyendo $\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})$, por su definición, nos queda:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})) = \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Después de operar un poco tenemos la función de la log-verosimilitud. Ahora falta hacer-la negativa, así que simplemente negaremos la función obtenida anteriormente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "- \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por el momento tendremos: \n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} = - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Podemos seguir simplificando y operando con esta función, hasta obtener:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} &= - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\\\\\n",
        "&= - \\sum_{i=1}^{n} (log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}) + log (exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} ((log (1) - log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})log(e))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (- log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (-\\frac{1}{2} log (2\\pi\\sigma^{2}) - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) + \\sum_{i=1}^{n} - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align} \n",
        "$$\n",
        "\n",
        "En esta última función obtenida, lo que nos interesará minimizar la pérdida cuadrática que tenemos en el segundo término. \n",
        "\n",
        "#### b) Encontrad los estimadores de máxima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$, a partir de la muestra.\n",
        "\n",
        "Ahora que tenemos la construcción de la función de la log-verosimilitud negativa de la muestra, podemos encontrar los estimadores de máxima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$ con ayuda de las derivadas parciales.\n",
        "\n",
        "Así pues mediante estas queremos encontrar el mejor valor para cada uno. Formalizado como:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\underset{\\sigma^{2}}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Entonces, para maximizar $\\mathcal{L(\\theta)}$ con respecto a los parámetros, $\\mu$ y $\\sigma^{2}$ debemos la derivada parcial de la función con respecto al parámetro que consideremos, establecer esa derivada parcial en cero, y resolver para el parámetro. Es decir:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\mu} := 0\\\\\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} := 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Empezamos con la derivada parcial en $\\mu$:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= 0 + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (\\sum_{i=1}^{n} - \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}}) (x_{i} - \\mu)^{2} + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (0 + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2} \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} -2(x_{i} - \\mu) \\\\\n",
        "&= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma más simple de la derivada parcial de nuestra función de verosimilitud con respecto a $\\mu$, así que igualamos a 0 para encontrar el mejor parámetro $\\mu$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - \\sum_{i=1}^{n} \\mu \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - n \\mu \\\\\n",
        "n \\mu &= \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\mu &= \\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\mu$ será: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si repetimos el proceso para el parámetro $\\sigma^{2}$, tendremos:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\ \n",
        "&= \\frac{-n}{2} \\frac{\\partial}{\\partial\\sigma^{2}}(log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2})) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (- \\frac{1}{2\\sigma^{2}} \\frac{\\partial}{\\partial\\sigma^{2}} \\sigma^{-2} (x_{i} - \\mu)^{2}))  \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma más simple de la derivada parcial de nuestra función de verosimilitud con respecto a $\\sigma^{2}$, así que igualamos a 0 para encontrar el mejor parámetro $\\sigma^{2}$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "0 &= -n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "n \\sigma^{2} &= \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\sigma^{2} &= \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\sigma^{2}$ será: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\sigma^{2} = \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "#### c) Demostrad que realmente son minimos(y no extremos cualquiera).\n",
        "\n",
        "Para poder demostrar que ambos estimadores: $\\hat \\sigma^{2}$ y $\\mu$ son mínimos nos seguiremos ayudando de las derivadas parciales. Tomaremos para cada parámetro, sus segundas derivadas parciales y estudiaremos la concavidad de la función log-verosimiltud. \n",
        "\n",
        "Para eso, bastará ver que ambas derivadas segundas son positivas para poder afirmar que ambos parámetros son mínimos. Formalizado como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Para no hacer pesada la lectura del apartado, daremos las expresiones analíticas directamente y justificaremos porque las derivadas son positivas.\n",
        "\n",
        "Para el parámetro $\\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Y para el parámetro $\\mu$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### d) Implementad la función de log verosimilitud usand JAX. Definid muestras (independientes) de tamaño 50, 500, 5000 para una distribución Gaussiana com $\\mu$ y $\\sigma$ de vuestra elección. Implementad un algoritmo de descenso del gradiente utilizando JAX para optimizar la log verosimilitud y estimar los parámetros de la distribución explorandola tasa de aprendizaje y el número máximo de iteraciones. Podéis emplear un valor $\\epsilon$ para acabr la optimización de $1e-10$ e inicializar los vallores de los parámetrosa un valor razonable que no esté ni demasiado lejos, ni demasiado cerca de los valores reales. Comparad el resultado con el cálculo que dan los estimadores teóricos y comentad el resultado\n",
        "\n",
        "#### e) No todo se comporta según una distribución Gaussiana. A veces nuestros datos son generados por varios procesos diferentes que siguen distribuciones Gausianas con parámetros diferentes, básicamente tenemos una distribución conjunta con varias modalidades. Escribid la función de densidad de probabilidad para una distribución que sigue la suma de $k$ Gaussianas (fijaos que ha de ser una distribución de probabilidad). Supongamos que tenemos dos máquinas que fabrican dos tipos de tornillos de distinta longitud con cierta varianza también distinta. Todos los tornillos acaban mezclados y queremos calcular cuáles son los parámetros de la distribución de cada máquina. Sabemos que cada máquina ha fabricado el mismo número de tornillos. Generad dos muestras (independientes) de igual tamaño (2500) para cada distribución usando el generador de muestras normales de JAX. Mirad como se trata la generación de muestras en el capítulo 3 para que sean independientes. Implementad un algoritmo de descenso de gradiente para optimizar los parámetros de las dos distribuciones con la muestra conjunta utilizando la función de log verosimilitud de la mezcla de dos gaussianas. Explorad diferentes valores para la tasa de aprendizaje y el número máximo de iteraciones.\n",
        "\n",
        "#### f) Emplear la misma tasa de aprendizaje durante toda la optimización puede evitar que lleguemos realmente cerca del óptimo. Modificad el algoritmo que habéis implementado para que la tasa de aprendizaje vaya atenuándose con el número de iteraciones multiplicándola por un valor cercano a 1 $(0,9999, 0.999, 0,99, \\dots, 0.9)$. Repetid la optimización de vuestro mejor resultado en el apartado anterior con diferentes atenuaciones. ¿Ha afectado al resultado? ¿Ha afectado al número de iteraciones antes de converger?"
      ],
      "metadata": {
        "id": "A15NzPxjXmwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) No todo se comporta según una distribución Gaussiana. A veces nuestros datos son generados por varios procesos diferentes que siguen distribuciones Gausianas con parámetros diferentes, básicamente tenemos una distribución conjunta con varias modalidades. Escribid la función de densidad de probabilidad para una distribución que sigue la suma de k Gaussianas (fijaos que ha de ser una distribución de probabilidad). Supongamos que tenemos dos máquinas que fabrican dos tipos de tornillos de distinta longitud con cierta varianza también distinta. Todos los tornillos acaban mezclados y queremos calcular cuáles son los parámetros de la distribución de cada máquina. Sabemos que cada máquina ha fabricado el mismo número de tornillos. Generad dos muestras (independientes) de igual tamaño (2500) para cada distribución usando el generador de muestras normales de JAX. Mirad como se trata la generación de muestras en el capítulo 3 para que sean independientes. Implementad un algoritmo de descenso de gradiente para optimizar los parámetros de las dos distribuciones con la muestra conjunta utilizando la función de log verosimilitud de la mezcla de dos gaussianas. Explorad diferentes valores para la tasa de aprendizaje y el número máximo de iteraciones.\n",
        "\n",
        "Assumiendo que las muestras son independientes entonces sabemos que su suma también se distribuye de forma nomal: \n",
        "\n",
        "$$ X\\sim N(\\mu _{X},\\sigma _{X}^{2})$$\n",
        "$$ Y\\sim N(\\mu _{Y},\\sigma _{Y}^{2})$$\n",
        "$$ Z = X + Y$$\n",
        "\n",
        "Con lo que equivaldrá a:\n",
        "\n",
        "$$ Z \\sim (\\mu _{Y}+\\mu _{X},\\sigma _{X}^{2}+\\sigma _{Y}^{2}) $$\n",
        "\n",
        "Este ejemplo con dos variables nos lleva a: \n",
        "\n",
        "$$ K \\sim \\sum \\limits_{i=1}^{n}(\\mu _{i},\\sigma_{i}^{2}) $$\n",
        "\n",
        "Teniendo en cuenta que la funcion de distribución es:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - (\\sum \\limits_{i=1}^{k}\\mu _{i})\n",
        ")^{2}}{2 \\sum \\limits_{}})\n",
        "\\end{align}\n",
        "\n",
        "$$\n",
        "\n",
        "Si aplicamos esta propiedad a la función de distribución usando unas muestras para $k$ distribuciones gaussianas de diferentes parametros: $\\vec{\\mu} = \\{ \\mu_1, ..., \\mu_k \\}$ i $\\vec{\\sigma} = \\{ \\sigma_1, ..., \\sigma_k \\}$ la función de densidad de probabilidad es: \n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "Crec que cal dir que assuimim que les k distribucions gaussianes son de k variables independents i que per tant la suma d'aquestes seguirà també una distribució normal. I per tant ara la nova $\\mu$ será: $n\\mu$ i la nova $\\sigma^{2}$ sera: $\\frac{\\sigma^{2}}{n}$ i per tant la funció considerada seria:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "&= \\frac{1}{\\sqrt{2\\pi\\frac{\\sigma^{2}}{n}}} exp(-\\frac{(x - \\mu_i)^{2}}{2\\frac{\\sigma_i^{2}}{n}}) \\\\\n",
        "&= \\frac{1}{\\sigma} \\sqrt{\\frac{n}{2\\pi}} exp(-\\frac{(x - \\mu_i)^{2}}{2\\frac{\\sigma_i^{2}}{n}})\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "57rzuLP-hvh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Implementad la función de log verosimilitud usando JAX. Definid muestras (independientes) de tamaños 50, 500 y 5000 para una distribución Gausiana con 𝜇 y 𝜎 de vuestra elección. Implementad un algoritmo de descenso de gradiente utilizando JAX para optimizar la log verosimilitud y estimar los parámetros de la distribución explorando la tasa de aprendizaje y el número máximo de iteraciones. Podéis emplear un valor de 𝜖 para acabar la optimización de\n",
        "1e-10 e inicializar los valores de los parámetros a un valor razonable que no este ni demasiado lejos, ni demasiado cerca de los valores reales. Comparad el resultado con el cálculo que dan los estimadores teóricos y comentad el resultado."
      ],
      "metadata": {
        "id": "ae8xTZsmdtOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "from jax import grad, vmap, jit, random, lax\n",
        "from numpy.random import seed\n",
        "from numpy.random import normal\n",
        "\n",
        "#generate data (3 gausiana n1 = 50, n2 = 500 y n3 = 5000)\n",
        "\n",
        "seed(56)  \n",
        "# always the same seed to get the same results\n",
        "\n",
        "sigma = 3\n",
        "media = 10\n",
        "\n",
        "data1 = normal(loc=media, scale=sigma, size=50) # loc = media, scale = varianza\n",
        "data2 = normal(loc=media, scale=sigma, size=500)\n",
        "data3 = normal(loc=media, scale=sigma, size=5000)\n",
        "print (\"Parametros de las muestras\")\n",
        "var1 = jnp.std(data1, ddof=1)\n",
        "var2 = jnp.std(data2, ddof=1)\n",
        "var3 = jnp.std(data3, ddof=1)\n",
        "print (\"Sigma1 \", var1)\n",
        "print (\"Sigma2 \",var2)\n",
        "print (\"Sigma3 \",var3)\n",
        "media1 = jnp.mean(data1)\n",
        "media2 = jnp.mean(data2)\n",
        "media3 = jnp.mean(data3)\n",
        "print (\"Media1 \", media1)\n",
        "print (\"Media2 \", media2)\n",
        "print (\"Media3 \", media3)\n",
        "\n",
        "\n",
        "def likelohood(mu, sigma, data):\n",
        "    n = data.shape\n",
        "    data = (data - mu)**2\n",
        "    sumatorio = jnp.sum(data)\n",
        "    print(sumatorio)\n",
        "    ll = -jnp.sum(-n/2 * jnp.log(2*jnp.pi*(sigma**2)) - (sumatorio/(2 * (sigma**2))))  #comprobar con lo de arriba apartado a\n",
        "    return ll\n",
        "\n",
        "\n",
        "def lossMAE(p, x, y):\n",
        "    n = jnp.abs(likelohood(p[1], p[0], x) - y)\n",
        "    print (n)\n",
        "    return n\n",
        "\n",
        "\n",
        "def lossMSE(p, x, y):\n",
        "    n = (likelohood(p,x) - y)**2\n",
        "    print (n)\n",
        "    return n\n",
        "\n",
        "\n",
        "\n",
        "#   descenso de gradiente Utilizando error cuadratico medio\n",
        "\n",
        "\n",
        "epsilon = 1e-10                                                         #precision en el delta  perdida (ploss- loss)\n",
        "lr = 2.0\n",
        "mu = 0.5                                             #parametros sigma y mu iniciales cualesquiera p[0]=sigma, p[1]=mu\n",
        "sigma = 13.0\n",
        "grad_likelohood = jit(grad(likelohood, argnums = [0,1]))             #derivamos para sigma y mu\n",
        "loss = vmap(grad_likelohood,in_axes=(None, None, 0))(sigma, mu, data3)\n",
        "print = loss\n",
        "for i in range(4000):\n",
        "    part = vmap(grad_likelohood,in_axes=(None,None,0))(sigma, mu, data3)\n",
        "    mu = mu - lr * part[1].mean(0)\n",
        "    sigma = sigma - lr * part[0].mean(0)\n",
        "    param = jnp.array([sigma,mu])\n",
        "    loss = vmap(grad_likelohood, in_axes=(None,None,0))(sigma, mu, data3).mean(0)\n",
        "    if loss < epsilon:\n",
        "        print(i)\n",
        "        break\n",
        "    plos = loss\n",
        "print(param, loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "T7CPZpRka54i",
        "outputId": "b2813f4c-d576-41d4-a51e-47cd8e81ba27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-91b714a4c00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_likelohood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_likelohood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ]
    }
  ]
}
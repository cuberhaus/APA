{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Primera lista - Problema GRUPAL 1\n",
        "\n",
        "Componentes del grupo:\n",
        "\n",
        "*   Pol Casacuberta Gil\n",
        "*   Joaquin Faraone Prieto\n",
        "*   Agnes Felip i D칤az \n",
        "*   Marta Granero i Mart칤\n",
        "\n",
        "## Dos mejor que una\n",
        "\n",
        "### Consideremos un experimento en el que medimos una determinada variable aleatoria $X$, que sigue una distribuci칩n Gaussiana univariante $(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2}))$. Tomamos n medidas independientes de $X$ y obtenemos una muestra aleatoria $\\{x_{1}, \\dots, x_{n}\\}$ donde cada $x_{i}$ es una realizaci칩n de $X$, para $i = 1, \\dots, n$. Resolved los siguentes apartados, ilustrando los resultados de la manera que os parezca m치s adecuada.\n",
        "\n",
        "\n",
        "#### a) Escribid la funci칩n de densidad de probabilidad para una $x_{i}$ cualquiera y construid la funci칩n log-verosimilitud(negativa) de la muestra.\n",
        "\n",
        "La expresion matem치tica que representa la funci칩n de densidad de una distribuci칩n normal para una $x_{i}$ es la siguiente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{N}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Una vez dada la expresi칩n de la funci칩n de densidad de la distribuci칩n normal para una $x_{i}$, nos piden construir la funci칩n de la log-verosimilitud negativa de la muestra.\n",
        "\n",
        "Esta funci칩n de la log-verosimilitud($\\mathcal{L}$) que vamos a construir, nos va a permitir encontrar los mejores parametros del modelo que se ajusten a los datos. O lo que es lo mismo, maximizaremos $\\mathcal{L(\\theta)}$ con respecto a los par치metros, $\\theta$. \n",
        "\n",
        "Lo expresaremos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; p(\\textbf X | \\theta) \n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si especificamos para nuestro caso, d칩nde p, sigue una distribuci칩n normal, tenemos:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\theta)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Notemos pues que: $\\mathcal{L(\\theta)} = p(\\textbf X | \\theta) = \\mathcal{N}(\\textbf X | \\theta)$\n",
        "\n",
        "Como bien sabemos los par치metros para una distribuci칩n gaussiana, son $\\mu$ y $\\sigma^{2}$. Entonces para una MLE de un modelo gaussiano, solo har치 falta encontrar buenas estimaciones de ambos par치metros usando derivadas parciales. \n",
        "\n",
        "Los par치metros $\\theta$ son: $\\mu, \\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\mu, \\sigma^{2})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora s칤, procedamos a construir la funci칩n:\n",
        "\n",
        "Como tratamos con n muestras, las quales son (iid), los par치metros a estimar deberan tener en cuenta todo el conjunto de datos, por lo tanto sumaremos la log-verosimilitud para cada muestra de datos $i$ que tenemos. Lo expresamos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "log (\\mathcal{N}(\\textbf X | \\theta)) = \\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2}))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora sustituyendo $\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})$, por su definici칩n, nos queda:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})) = \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Despu칠s de operar un poco tenemos la funci칩n de la log-verosimilitud. Ahora falta hacer-la negativa, as칤 que simplemente negaremos la funci칩n obtenida anteriormente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "- \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por el momento tendremos: \n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} = - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Podemos seguir simplificando y operando con esta funci칩n, hasta obtener:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} &= - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\\\\\n",
        "&= - \\sum_{i=1}^{n} (log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}) + log (exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} ((log (1) - log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})log(e))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (- log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (-\\frac{1}{2} log (2\\pi\\sigma^{2}) - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) + \\sum_{i=1}^{n} - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align} \n",
        "$$\n",
        "\n",
        "En esta 칰ltima funci칩n obtenida, lo que nos interesar치 minimizar la p칠rdida cuadr치tica que tenemos en el segundo t칠rmino. \n",
        "\n",
        "#### b) Encontrad los estimadores de m치xima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$, a partir de la muestra.\n",
        "\n",
        "Ahora que tenemos la construcci칩n de la funci칩n de la log-verosimilitud negativa de la muestra, podemos encontrar los estimadores de m치xima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$ con ayuda de las derivadas parciales.\n",
        "\n",
        "As칤 pues mediante estas queremos encontrar el mejor valor para cada uno. Formalizado como:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\underset{\\sigma^{2}}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Entonces, para maximizar $\\mathcal{L(\\theta)}$ con respecto a los par치metros, $\\mu$ y $\\sigma^{2}$ debemos la derivada parcial de la funci칩n con respecto al par치metro que consideremos, establecer esa derivada parcial en cero, y resolver para el par치metro. Es decir:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\mu} := 0\\\\\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} := 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Empezamos con la derivada parcial en $\\mu$:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= 0 + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (\\sum_{i=1}^{n} - \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}}) (x_{i} - \\mu)^{2} + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (0 + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2} \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} -2(x_{i} - \\mu) \\\\\n",
        "&= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma m치s simple de la derivada parcial de nuestra funci칩n de verosimilitud con respecto a $\\mu$, as칤 que igualamos a 0 para encontrar el mejor par치metro $\\mu$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - \\sum_{i=1}^{n} \\mu \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - n \\mu \\\\\n",
        "n \\mu &= \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\mu &= \\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\mu$ ser치: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si repetimos el proceso para el par치metro $\\sigma^{2}$, tendremos:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\ \n",
        "&= \\frac{-n}{2} \\frac{\\partial}{\\partial\\sigma^{2}}(log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2})) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (- \\frac{1}{2\\sigma^{2}} \\frac{\\partial}{\\partial\\sigma^{2}} \\sigma^{-2} (x_{i} - \\mu)^{2}))  \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma m치s simple de la derivada parcial de nuestra funci칩n de verosimilitud con respecto a $\\sigma^{2}$, as칤 que igualamos a 0 para encontrar el mejor par치metro $\\sigma^{2}$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "0 &= -n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "n \\sigma^{2} &= \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\sigma^{2} &= \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\sigma^{2}$ ser치: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\sigma^{2} = \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "#### c) Demostrad que realmente son minimos(y no extremos cualquiera).\n",
        "\n",
        "Para poder demostrar que ambos estimadores: $\\hat \\sigma^{2}$ y $\\mu$ son m칤nimos nos seguiremos ayudando de las derivadas parciales. Tomaremos para cada par치metro, sus segundas derivadas parciales y estudiaremos la concavidad de la funci칩n log-verosimiltud. \n",
        "\n",
        "Para eso, bastar치 ver que ambas derivadas segundas son positivas para poder afirmar que ambos par치metros son m칤nimos. Formalizado como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Para no hacer pesada la lectura del apartado, daremos las expresiones anal칤ticas directamente y justificaremos porque las derivadas son positivas.\n",
        "\n",
        "Para el par치metro $\\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Y para el par치metro $\\mu$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### d) Implementad la funci칩n de log verosimilitud usand JAX. Definid muestras (independientes) de tama침o 50, 500, 5000 para una distribuci칩n Gaussiana com $\\mu$ y $\\sigma$ de vuestra elecci칩n. Implementad un algoritmo de descenso del gradiente utilizando JAX para optimizar la log verosimilitud y estimar los par치metros de la distribuci칩n explorandola tasa de aprendizaje y el n칰mero m치ximo de iteraciones. Pod칠is emplear un valor $\\epsilon$ para acabr la optimizaci칩n de $1e-10$ e inicializar los vallores de los par치metrosa un valor razonable que no est칠 ni demasiado lejos, ni demasiado cerca de los valores reales. Comparad el resultado con el c치lculo que dan los estimadores te칩ricos y comentad el resultado\n",
        "\n",
        "#### e) No todo se comporta seg칰n una distribuci칩n Gaussiana. A veces nuestros datos son generados por varios procesos diferentes que siguen distribuciones Gausianas con par치metros diferentes, b치sicamente tenemos una distribuci칩n conjunta con varias modalidades. Escribid la funci칩n de densidad de probabilidad para una distribuci칩n que sigue la suma de $k$ Gaussianas (fijaos que ha de ser una distribuci칩n de probabilidad). Supongamos que tenemos dos m치quinas que fabrican dos tipos de tornillos de distinta longitud con cierta varianza tambi칠n distinta. Todos los tornillos acaban mezclados y queremos calcular cu치les son los par치metros de la distribuci칩n de cada m치quina. Sabemos que cada m치quina ha fabricado el mismo n칰mero de tornillos. Generad dos muestras (independientes) de igual tama침o (2500) para cada distribuci칩n usando el generador de muestras normales de JAX. Mirad como se trata la generaci칩n de muestras en el cap칤tulo 3 para que sean independientes. Implementad un algoritmo de descenso de gradiente para optimizar los par치metros de las dos distribuciones con la muestra conjunta utilizando la funci칩n de log verosimilitud de la mezcla de dos gaussianas. Explorad diferentes valores para la tasa de aprendizaje y el n칰mero m치ximo de iteraciones.\n",
        "\n",
        "#### f) Emplear la misma tasa de aprendizaje durante toda la optimizaci칩n puede evitar que lleguemos realmente cerca del 칩ptimo. Modificad el algoritmo que hab칠is implementado para que la tasa de aprendizaje vaya atenu치ndose con el n칰mero de iteraciones multiplic치ndola por un valor cercano a 1 $(0,9999, 0.999, 0,99, \\dots, 0.9)$. Repetid la optimizaci칩n de vuestro mejor resultado en el apartado anterior con diferentes atenuaciones. 쮿a afectado al resultado? 쮿a afectado al n칰mero de iteraciones antes de converger?"
      ],
      "metadata": {
        "id": "A15NzPxjXmwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) No todo se comporta seg칰n una distribuci칩n Gaussiana. A veces nuestros datos son generados por varios procesos diferentes que siguen distribuciones Gausianas con par치metros diferentes, b치sicamente tenemos una distribuci칩n conjunta con varias modalidades. Escribid la funci칩n de densidad de probabilidad para una distribuci칩n que sigue la suma de k Gaussianas (fijaos que ha de ser una distribuci칩n de probabilidad). Supongamos que tenemos dos m치quinas que fabrican dos tipos de tornillos de distinta longitud con cierta varianza tambi칠n distinta. Todos los tornillos acaban mezclados y queremos calcular cu치les son los par치metros de la distribuci칩n de cada m치quina. Sabemos que cada m치quina ha fabricado el mismo n칰mero de tornillos. Generad dos muestras (independientes) de igual tama침o (2500) para cada distribuci칩n usando el generador de muestras normales de JAX. Mirad como se trata la generaci칩n de muestras en el cap칤tulo 3 para que sean independientes. Implementad un algoritmo de descenso de gradiente para optimizar los par치metros de las dos distribuciones con la muestra conjunta utilizando la funci칩n de log verosimilitud de la mezcla de dos gaussianas. Explorad diferentes valores para la tasa de aprendizaje y el n칰mero m치ximo de iteraciones.\n",
        "\n",
        "Assumiendo que las muestras son independientes entonces sabemos que su suma tambi칠n se distribuye de forma nomal: \n",
        "\n",
        "$$ X\\sim N(\\mu _{X},\\sigma _{X}^{2})$$\n",
        "$$ Y\\sim N(\\mu _{Y},\\sigma _{Y}^{2})$$\n",
        "$$ Z = X + Y$$\n",
        "\n",
        "Con lo que equivaldr치 a:\n",
        "\n",
        "$$ Z \\sim (\\mu _{Y}+\\mu _{X},\\sigma _{X}^{2}+\\sigma _{Y}^{2}) $$\n",
        "\n",
        "Este ejemplo con dos variables nos lleva a: \n",
        "\n",
        "$$ K \\sim \\sum \\limits_{i=1}^{n}(\\mu _{i},\\sigma_{i}^{2}) $$\n",
        "\n",
        "Teniendo en cuenta que la funcion de distribuci칩n es:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - (\\sum \\limits_{i=1}^{k}\\mu _{i})\n",
        ")^{2}}{2 \\sum \\limits_{}})\n",
        "\\end{align}\n",
        "\n",
        "$$\n",
        "\n",
        "Si aplicamos esta propiedad a la funci칩n de distribuci칩n usando unas muestras para $k$ distribuciones gaussianas de diferentes parametros: $\\vec{\\mu} = \\{ \\mu_1, ..., \\mu_k \\}$ i $\\vec{\\sigma} = \\{ \\sigma_1, ..., \\sigma_k \\}$ la funci칩n de densidad de probabilidad es: \n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "Crec que cal dir que assuimim que les k distribucions gaussianes son de k variables independents i que per tant la suma d'aquestes seguir tamb칠 una distribuci칩 normal. I per tant ara la nova $\\mu$ ser치: $n\\mu$ i la nova $\\sigma^{2}$ sera: $\\frac{\\sigma^{2}}{n}$ i per tant la funci칩 considerada seria:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "&= \\frac{1}{\\sqrt{2\\pi\\frac{\\sigma^{2}}{n}}} exp(-\\frac{(x - \\mu_i)^{2}}{2\\frac{\\sigma_i^{2}}{n}}) \\\\\n",
        "&= \\frac{1}{\\sigma} \\sqrt{\\frac{n}{2\\pi}} exp(-\\frac{(x - \\mu_i)^{2}}{2\\frac{\\sigma_i^{2}}{n}})\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "57rzuLP-hvh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Implementad la funci칩n de log verosimilitud usando JAX. Definid muestras (independientes) de tama침os 50, 500 y 5000 para una distribuci칩n Gausiana con 洧랞 y 洧랥 de vuestra elecci칩n. Implementad un algoritmo de descenso de gradiente utilizando JAX para optimizar la log verosimilitud y estimar los par치metros de la distribuci칩n explorando la tasa de aprendizaje y el n칰mero m치ximo de iteraciones. Pod칠is emplear un valor de 洧랬 para acabar la optimizaci칩n de\n",
        "1e-10 e inicializar los valores de los par치metros a un valor razonable que no este ni demasiado lejos, ni demasiado cerca de los valores reales. Comparad el resultado con el c치lculo que dan los estimadores te칩ricos y comentad el resultado."
      ],
      "metadata": {
        "id": "ae8xTZsmdtOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "from jax import grad, vmap, jit, random, lax\n",
        "from numpy.random import seed\n",
        "from numpy.random import normal\n",
        "\n",
        "#generate data (3 gausiana n1 = 50, n2 = 500 y n3 = 5000)\n",
        "\n",
        "seed(56)  \n",
        "# always the same seed to get the same results\n",
        "\n",
        "sigma = 3\n",
        "media = 10\n",
        "\n",
        "data1 = normal(loc=media, scale=sigma, size=50) # loc = media, scale = varianza\n",
        "data2 = normal(loc=media, scale=sigma, size=500)\n",
        "data3 = normal(loc=media, scale=sigma, size=5000)\n",
        "print (\"Parametros de las muestras\")\n",
        "var1 = jnp.std(data1, ddof=1)\n",
        "var2 = jnp.std(data2, ddof=1)\n",
        "var3 = jnp.std(data3, ddof=1)\n",
        "print (\"Sigma1 \", var1)\n",
        "print (\"Sigma2 \",var2)\n",
        "print (\"Sigma3 \",var3)\n",
        "media1 = jnp.mean(data1)\n",
        "media2 = jnp.mean(data2)\n",
        "media3 = jnp.mean(data3)\n",
        "print (\"Media1 \", media1)\n",
        "print (\"Media2 \", media2)\n",
        "print (\"Media3 \", media3)\n",
        "\n",
        "\n",
        "def likelohood(mu, sigma, data):\n",
        "    n = data.shape\n",
        "    data = (data - mu)**2\n",
        "    sumatorio = jnp.sum(data)\n",
        "    print(sumatorio)\n",
        "    ll = -jnp.sum(-n/2 * jnp.log(2*jnp.pi*(sigma**2)) - (sumatorio/(2 * (sigma**2))))  #comprobar con lo de arriba apartado a\n",
        "    return ll\n",
        "\n",
        "\n",
        "def lossMAE(p, x, y):\n",
        "    n = jnp.abs(likelohood(p[1], p[0], x) - y)\n",
        "    print (n)\n",
        "    return n\n",
        "\n",
        "\n",
        "def lossMSE(p, x, y):\n",
        "    n = (likelohood(p,x) - y)**2\n",
        "    print (n)\n",
        "    return n\n",
        "\n",
        "\n",
        "\n",
        "#   descenso de gradiente Utilizando error cuadratico medio\n",
        "\n",
        "\n",
        "epsilon = 1e-10                                                         #precision en el delta  perdida (ploss- loss)\n",
        "lr = 2.0\n",
        "mu = 0.5                                             #parametros sigma y mu iniciales cualesquiera p[0]=sigma, p[1]=mu\n",
        "sigma = 13.0\n",
        "grad_likelohood = jit(grad(likelohood, argnums = [0,1]))             #derivamos para sigma y mu\n",
        "loss = vmap(grad_likelohood,in_axes=(None, None, 0))(sigma, mu, data3)\n",
        "print = loss\n",
        "for i in range(4000):\n",
        "    part = vmap(grad_likelohood,in_axes=(None,None,0))(sigma, mu, data3)\n",
        "    mu = mu - lr * part[1].mean(0)\n",
        "    sigma = sigma - lr * part[0].mean(0)\n",
        "    param = jnp.array([sigma,mu])\n",
        "    loss = vmap(grad_likelohood, in_axes=(None,None,0))(sigma, mu, data3).mean(0)\n",
        "    if loss < epsilon:\n",
        "        print(i)\n",
        "        break\n",
        "    plos = loss\n",
        "print(param, loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "T7CPZpRka54i",
        "outputId": "b2813f4c-d576-41d4-a51e-47cd8e81ba27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-91b714a4c00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_likelohood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_likelohood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ]
    }
  ]
}
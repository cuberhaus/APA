{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Primera lista - Problema GRUPAL 1\n",
        "\n",
        "Componentes del grupo:\n",
        "\n",
        "*   Pol Casacuberta Gil\n",
        "*   Joaquin Faraone Prieto\n",
        "*   Agnes Felip i Díaz \n",
        "*   Marta Granero i Martí\n",
        "\n",
        "## Dos mejor que una\n",
        "\n",
        "### Consideremos un experimento en el que medimos una determinada variable aleatoria $X$, que sigue una distribución Gaussiana univariante $(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2}))$. Tomamos n medidas independientes de $X$ y obtenemos una muestra aleatoria $\\{x_{1}, \\dots, x_{n}\\}$ donde cada $x_{i}$ es una realización de $X$, para $i = 1, \\dots, n$. Resolved los siguentes apartados, ilustrando los resultados de la manera que os parezca más adecuada.\n",
        "\n",
        "\n",
        "#### a) Escribid la función de densidad de probabilidad para una $x_{i}$ cualquiera y construid la función log-verosimilitud(negativa) de la muestra.\n",
        "\n",
        "La expresion matemática que representa la función de densidad de una distribución normal para una $x_{i}$ es la siguiente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{N}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Una vez dada la expresión de la función de densidad de la distribución normal para una $x_{i}$, nos piden construir la función de la log-verosimilitud negativa de la muestra.\n",
        "\n",
        "Esta función de la log-verosimilitud($\\mathcal{L}$) que vamos a construir, nos va a permitir encontrar los mejores parametros del modelo que se ajusten a los datos. O lo que es lo mismo, maximizaremos $\\mathcal{L(\\theta)}$ con respecto a los parámetros, $\\theta$. \n",
        "\n",
        "Lo expresaremos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; p(\\textbf X | \\theta) \n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si especificamos para nuestro caso, dónde p, sigue una distribución normal, tenemos:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\theta)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Notemos pues que: $\\mathcal{L(\\theta)} = p(\\textbf X | \\theta) = \\mathcal{N}(\\textbf X | \\theta)$\n",
        "\n",
        "Como bien sabemos los parámetros para una distribución gaussiana, son $\\mu$ y $\\sigma^{2}$. Entonces para una MLE de un modelo gaussiano, solo hará falta encontrar buenas estimaciones de ambos parámetros usando derivadas parciales. \n",
        "\n",
        "Los parámetros $\\theta$ son: $\\mu, \\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta = \\underset{\\theta}{argmax} \\; \\mathcal{N}(\\textbf X | \\mu, \\sigma^{2})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora sí, procedamos a construir la función:\n",
        "\n",
        "Como tratamos con n muestras, las quales son (iid), los parámetros a estimar deberan tener en cuenta todo el conjunto de datos, por lo tanto sumaremos la log-verosimilitud para cada muestra de datos $i$ que tenemos. Lo expresamos como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "log (\\mathcal{N}(\\textbf X | \\theta)) = \\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2}))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora sustituyendo $\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})$, por su definición, nos queda:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{i=1}^{n} log (\\mathcal{N}(\\textbf x_{i} | \\mu, \\sigma^{2})) = \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Después de operar un poco tenemos la función de la log-verosimilitud. Ahora falta hacer-la negativa, así que simplemente negaremos la función obtenida anteriormente:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "- \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por el momento tendremos: \n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} = - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Podemos seguir simplificando y operando con esta función, hasta obtener:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{L(\\theta)} &= - \\sum_{i=1}^{n} log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\\\\\n",
        "&= - \\sum_{i=1}^{n} (log (\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}) + log (exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} ((log (1) - log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})log(e))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (- log (\\sqrt{2\\pi\\sigma^{2}}) + log (\\frac{-1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}))) \\\\\n",
        "&= - \\sum_{i=1}^{n} (-\\frac{1}{2} log (2\\pi\\sigma^{2}) - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) + \\sum_{i=1}^{n} - \\frac{1}{2}(\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}) \\\\\n",
        "&= - \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align} \n",
        "$$\n",
        "\n",
        "En esta última función obtenida, lo que nos interesará minimizar la pérdida cuadrática que tenemos en el segundo término. \n",
        "\n",
        "#### b) Encontrad los estimadores de máxima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$, a partir de la muestra.\n",
        "\n",
        "Ahora que tenemos la construcción de la función de la log-verosimilitud negativa de la muestra, podemos encontrar los estimadores de máxima verosimilitud $\\hat \\mu$ y $\\hat \\sigma^{2}$ con ayuda de las derivadas parciales.\n",
        "\n",
        "Así pues mediante estas queremos encontrar el mejor valor para cada uno. Formalizado como:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\underset{\\sigma^{2}}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Entonces, para maximizar $\\mathcal{L(\\theta)}$ con respecto a los parámetros, $\\mu$ y $\\sigma^{2}$ debemos la derivada parcial de la función con respecto al parámetro que consideremos, establecer esa derivada parcial en cero, y resolver para el parámetro. Es decir:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\mu} := 0\\\\\n",
        "\\underset{\\mu}{argmax} \\; \\mathcal{L}(\\textbf X | \\mu, \\sigma^{2})  = \\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} := 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Empezamos con la derivada parcial en $\\mu$:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= 0 + \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{\\partial}{\\partial\\mu} (\\sum_{i=1}^{n} - \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\mu} (- \\frac{1}{2\\sigma^{2}}) (x_{i} - \\mu)^{2} + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\sum_{i=1}^{n} (0 + (-\\frac{1}{2\\sigma^{2}}) \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2}) \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial\\mu}(x_{i} - \\mu)^{2} \\\\\n",
        "&= -\\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} -2(x_{i} - \\mu) \\\\\n",
        "&= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma más simple de la derivada parcial de nuestra función de verosimilitud con respecto a $\\mu$, así que igualamos a 0 para encontrar el mejor parámetro $\\mu$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\mu} &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} (x_{i} - \\mu) \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - \\sum_{i=1}^{n} \\mu \\\\\n",
        "0 &= \\sum_{i=1}^{n} x_{i} - n \\mu \\\\\n",
        "n \\mu &= \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\mu &= \\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\mu$ será: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_{i}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si repetimos el proceso para el parámetro $\\sigma^{2}$, tendremos:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{n}{2} \\; log (2\\pi\\sigma^{2}) - \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\ \n",
        "&= \\frac{-n}{2} \\frac{\\partial}{\\partial\\sigma^{2}}(log (2\\pi\\sigma^{2})) + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (\\frac{\\partial}{\\partial\\sigma^{2}}(- \\frac{1}{2\\sigma^{2}} (x_{i} - \\mu)^{2})) \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{-n}{2\\sigma^{2}} + \\sum_{i=1}^{n} (- \\frac{1}{2\\sigma^{2}} \\frac{\\partial}{\\partial\\sigma^{2}} \\sigma^{-2} (x_{i} - \\mu)^{2}))  \\\\\n",
        "&= \\dots \\\\\n",
        "&= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Ahora, tenemos la forma más simple de la derivada parcial de nuestra función de verosimilitud con respecto a $\\sigma^{2}$, así que igualamos a 0 para encontrar el mejor parámetro $\\sigma^{2}$.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial\\sigma^{2}} &= \\frac{1}{2\\sigma^{2}}(-n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}) \\\\\n",
        "0 &= -n + \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "n \\sigma^{2} &= \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\sigma^{2} &= \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto el mejor estimador para $\\sigma^{2}$ será: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat \\sigma^{2} = \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} - \\mu)^{2}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "#### c) Demostrad que realmente son minimos(y no extremos cualquiera).\n",
        "\n",
        "Para poder demostrar que ambos estimadores: $\\hat \\sigma^{2}$ y $\\mu$ son mínimos nos seguiremos ayudando de las derivadas parciales. Tomaremos para cada parámetro, sus segundas derivadas parciales y estudiaremos la concavidad de la función log-verosimiltud. \n",
        "\n",
        "Para eso, bastará ver que ambas derivadas segundas son positivas para poder afirmar que ambos parámetros son mínimos. Formalizado como:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} > 0 \\; ; \\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu} > 0 \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Para no hacer pesada la lectura del apartado, daremos las expresiones analíticas directamente y justificaremos porque las derivadas son positivas.\n",
        "\n",
        "Para el parámetro $\\mu$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu^{2}} &= n\\frac{1}{\\sigma^{2}} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Y para el parámetro $\\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} = \\frac{1}{\\frac{1}{\\sigma^{2}}} &= \\sigma^{2} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Como podemos observar ambas derivadas parciales segundas con respecto al parámetro $\\mu$ y al parámetro $\\sigma^{2}$ son positivas. Estas seran positivas en todo su dominio, ya que tanto $n$ como $\\sigma^{2}$ siempre tomaran valores positivos, por lo tanto, no solo son extremos, sino que son mínimos.\n",
        "\n",
        "Formalizado para el parámetro $\\mu$ y $\\sigma^{2}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\mu^{2}} = n\\frac{1}{\\sigma^{2}} > 0; \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial^{2}\\mathcal{L}}{\\partial^{2}\\sigma^{2}} = \\frac{1}{\\frac{1}{\\sigma^{2}}} = \\sigma^{2} > 0\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Por lo tanto, podemo afirmar que la función negativa de la log-verosimilitud para la distribución gaussiana es no concava, y por lo tanto convexa para el parámetro que representa la media y para el parámetro de la varianza.\n",
        "\n",
        "Notamos, que la función de la log-verosimilitud será concava para ambos parámetros."
      ],
      "metadata": {
        "id": "A15NzPxjXmwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### d) Implementad la función de log verosimilitud usand JAX. Definid muestras (independientes) de tamaño 50, 500, 5000 para una distribución Gaussiana com $\\mu$ y $\\sigma$ de vuestra elección. Implementad un algoritmo de descenso del gradiente utilizando JAX para optimizar la log verosimilitud y estimar los parámetros de la distribución explorandola tasa de aprendizaje y el número máximo de iteraciones. Podéis emplear un valor $\\epsilon$ para acabr la optimización de $1e-10$ e inicializar los vallores de los parámetrosa un valor razonable que no esté ni demasiado lejos, ni demasiado cerca de los valores reales. Comparad el resultado con el cálculo que dan los estimadores teóricos y comentad el resultado"
      ],
      "metadata": {
        "id": "vqyXli9RNFsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "from jax import grad, vmap, jit, random, lax\n",
        "from numpy.random import seed\n",
        "from numpy.random import normal\n",
        "from jax.scipy.stats import norm\n",
        "\n",
        "rng = np.random.default_rng(42) # semilla para fijar la experimentación\n",
        "\n",
        "#Valores reales\n",
        "sigma = 3\n",
        "media = 10\n",
        "\n",
        "#(iid) de tamaño 50\n",
        "data1 = rng.normal(loc=media, scale=sigma, size=50)\n",
        "#(iid) de tamaño 500\n",
        "data2 = rng.normal(loc=media, scale=sigma, size=500)\n",
        "#(iid) de tamaño 5000\n",
        "data3 = rng.normal(loc=media, scale=sigma, size=5000)\n",
        "\n",
        "print (\"Parámetros de las muestras:\")\n",
        "var1 = jnp.std(data1, ddof=1)\n",
        "var2 = jnp.std(data2, ddof=1)\n",
        "var3 = jnp.std(data3, ddof=1)\n",
        "\n",
        "print (\"Sigma1: \", var1)\n",
        "print (\"Sigma2: \",var2)\n",
        "print (\"Sigma3: \",var3)\n",
        "\n",
        "media1 = jnp.mean(data1)\n",
        "media2 = jnp.mean(data2)\n",
        "media3 = jnp.mean(data3)\n",
        "print (\"Media1: \", media1)\n",
        "print (\"Media2: \", media2)\n",
        "print (\"Media3: \", media3)\n",
        "\n",
        "def estimate_mu_sigma(data):\n",
        "    epsilon = 1e-6\n",
        "    lr = 0.5\n",
        "    n_iter = 10000\n",
        "\n",
        "    #Valores que suponemos inicialmente\n",
        "    mu = 15.0\n",
        "    sigma = 10.0\n",
        "\n",
        "\n",
        "    grad_likelohood_mu = jit(grad(likelohood, argnums = 0)) \n",
        "    grad_likelohood_sigma = jit(grad(likelohood, argnums = 1))\n",
        "\n",
        "    grad_mu_mean = 0\n",
        "    grad_sigma_mean = 0  \n",
        "    for i in range(n_iter):\n",
        "        gradiente_mu = vmap(grad_likelohood_mu,in_axes=(None, None, 0))(mu, sigma, data)\n",
        "        gradiente_sigma = vmap(grad_likelohood_sigma,in_axes=(None, None, 0))(mu, sigma, data)\n",
        "\n",
        "        grad_mu_mean = jnp.mean(gradiente_mu)\n",
        "        grad_sigma_mean = jnp.mean(gradiente_sigma)\n",
        "\n",
        "        mu = mu - (lr * grad_mu_mean)\n",
        "        sigma = sigma - (lr * grad_sigma_mean)\n",
        "        if grad_mu_mean < epsilon and grad_sigma_mean < epsilon: \n",
        "            print(\"hemos llegado al minimo\")\n",
        "            print(i)\n",
        "            break\n",
        "    print(\"sigma: \" + str(sigma), \"mu: \" + str(mu))\n",
        "\n",
        "def likelohood(mu, sigma, data):\n",
        "    n = data.size\n",
        "    ll = (1/(2*sigma**2)) *  jnp.sum((data-mu)**2) + (n/2)*jnp.log(sigma**2) + (n/2)*jnp.log(2*jnp.pi)\n",
        "    return ll\n",
        "\n",
        "print(\"data1:\")\n",
        "estimate_mu_sigma(data1)\n",
        "print(\"data2:\")\n",
        "estimate_mu_sigma(data2)\n",
        "print(\"data3:\")\n",
        "estimate_mu_sigma(data3)"
      ],
      "metadata": {
        "id": "x8V8gGMcM9Vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f416c99-ae2a-488e-e416-66f86b0fe19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parámetros de las muestras:\n",
            "Sigma1:  2.3048317\n",
            "Sigma2:  2.9645505\n",
            "Sigma3:  3.0020196\n",
            "Media1:  10.273633\n",
            "Media2:  9.919176\n",
            "Media3:  9.950218\n",
            "data1:\n",
            "hemos llegado al minimo\n",
            "254\n",
            "sigma: 2.2816672 mu: 10.273638\n",
            "data2:\n",
            "hemos llegado al minimo\n",
            "343\n",
            "sigma: 2.961585 mu: 9.919183\n",
            "data3:\n",
            "hemos llegado al minimo\n",
            "349\n",
            "sigma: 3.0017204 mu: 9.950227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observaciones:\n",
        "Hemos implementado un algoritmo de descenso de gradiente y jugando un poco con los paràmetros learning rate $lr$ y con el número máximo de iteraciones. Parece que con un learning rate de 0.5 y unas 10.000 iteraciones se consiguen resultados muy cercanos a los estimadores teóricos de $\\mu$ y $\\sigma^{2}$."
      ],
      "metadata": {
        "id": "xMAqQRbtVy8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) No todo se comporta según una distribución Gaussiana. A veces nuestros datos son generados por varios procesos diferentes que siguen distribuciones Gausianas con parámetros diferentes, básicamente tenemos una distribución conjunta con varias modalidades. Escribid la función de densidad de probabilidad para una distribución que sigue la suma de k Gaussianas (fijaos que ha de ser una distribución de probabilidad). Supongamos que tenemos dos máquinas que fabrican dos tipos de tornillos de distinta longitud con cierta varianza también distinta. Todos los tornillos acaban mezclados y queremos calcular cuáles son los parámetros de la distribución de cada máquina. Sabemos que cada máquina ha fabricado el mismo número de tornillos. Generad dos muestras (independientes) de igual tamaño (2500) para cada distribución usando el generador de muestras normales de JAX. Mirad como se trata la generación de muestras en el capítulo 3 para que sean independientes. Implementad un algoritmo de descenso de gradiente para optimizar los parámetros de las dos distribuciones con la muestra conjunta utilizando la función de log verosimilitud de la mezcla de dos gaussianas. Explorad diferentes valores para la tasa de aprendizaje y el número máximo de iteraciones.\n",
        "\n",
        "Assumiendo que las muestras son independientes entonces sabemos que su suma también se distribuye de forma nomal: \n",
        "\n",
        "$$ X\\sim N(\\mu _{X},\\sigma _{X}^{2})$$\n",
        "$$ Y\\sim N(\\mu _{Y},\\sigma _{Y}^{2})$$\n",
        "$$ Z = X + Y$$\n",
        "\n",
        "Con lo que equivaldrá a:\n",
        "\n",
        "$$ Z \\sim (\\mu _{Y}+\\mu _{X},\\sigma _{X}^{2}+\\sigma _{Y}^{2}) $$\n",
        "\n",
        "\n",
        "Este ejemplo con dos variables nos lleva a: \n",
        "\n",
        "$$ K \\sim \\sum \\limits_{i=1}^{n}(\\mu _{i},\\sigma_{i}^{2}) $$\n",
        "\n",
        "\n",
        "Teniendo en cuenta que la funcion de distribución es:\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Si aplicamos esta propiedad a la función de distribución usando unas muestras para $k$ distribuciones gaussianas de diferentes parametros: $\\vec{\\mu} = \\{ \\mu_1, ..., \\mu_k \\}$ i $\\vec{\\sigma} = \\{ \\sigma_1, ..., \\sigma_k \\}$ pero generalmente la mediana y varianza de la suma de K variables independientes distribuidas de forma identica se da por $\\mu_K=K\\mu$ y $\\sigma_K=K\\sigma^{2}$ con lo que la funcion de distribucion resultante es:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathcal{f}(\\textbf x_{i}| \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi K\\sigma^{2}}}exp(-\\frac{(x_{i} - \\mu_K)^{2}}{2\\sigma_K^{2}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "57rzuLP-hvh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import math\n",
        "from jax import grad, vmap, jit, random\n",
        "from scipy import stats\n",
        "rng = np.random.default_rng(42)\n",
        "mu = 10\n",
        "sigma = 3\n",
        "data1 = rng.normal(loc=mu, scale=sigma, size=2500)\n",
        "\n",
        "mu2 = 15\n",
        "sigma2 = 2\n",
        "data2 = rng.normal(loc=mu2, scale=sigma2, size=2500)\n",
        "\n",
        "data = np.concatenate((data1, data2))\n",
        "\n",
        "def estimate_mu_sigma_E(data):\n",
        "    epsilon = 1e-10\n",
        "    lr = 0.5\n",
        "    mu = [12.0, 2.0]\n",
        "    sigma = [16.0, 4.0]\n",
        "    grad_likelohood_mu = jit(grad(likelihood_two, argnums=0))\n",
        "    grad_likelohood_sigma = jit(grad(likelihood_two, argnums=1))\n",
        "    grad_mu_mean = [0, 0] \n",
        "    grad_sigma_mean = [0, 0]\n",
        "    for i in range(10000):\n",
        "        gradiente_mu = vmap(grad_likelohood_mu, in_axes=(\n",
        "            None, None, 0))(mu, sigma, data)\n",
        "        gradiente_sigma = vmap(grad_likelohood_sigma,\n",
        "                               in_axes=(None, None, 0))(mu, sigma, data)\n",
        "        grad_mu_mean[0] = jnp.mean(gradiente_mu[0])\n",
        "        grad_mu_mean[1] = jnp.mean(gradiente_mu[1])\n",
        "        grad_sigma_mean[0] = jnp.mean(gradiente_sigma[0])\n",
        "        grad_sigma_mean[1] = jnp.mean(gradiente_sigma[1])\n",
        "        mu[0] = mu[0] - (lr * grad_mu_mean[0])\n",
        "        mu[1] = mu[1] - (lr * grad_mu_mean[1])\n",
        "        sigma[0] = sigma[0] - (lr * grad_sigma_mean[0])\n",
        "        sigma[1] = sigma[1] - (lr * grad_sigma_mean[1])\n",
        "        if grad_mu_mean[0] < epsilon and grad_sigma_mean[0] < epsilon and grad_mu_mean[1] < epsilon and grad_sigma_mean[1] < epsilon:\n",
        "            print(\"hemos llegado al minimo\")\n",
        "            print(i)\n",
        "            break\n",
        "    print(\"mu 1: \" + str(mu[0]))\n",
        "    print(\"sigma 1: \" + str(sigma[0]))\n",
        "    print(\"mu 2: \" + str(mu[1]))\n",
        "    print(\"sigma 2: \" + str(sigma[1]))\n",
        "\n",
        "\n",
        "def likelihood_two(mu, sigma, data):\n",
        "    n = data.size\n",
        "    ll = (1/(2*(sigma[0]**2+sigma[1]**2))) * jnp.sum((data-(mu[0] + mu[1]))**2) + (n/2)*jnp.log((sigma[0]**2+ sigma[1]**2)) + (n/2)*jnp.log(2*jnp.pi)\n",
        "    return ll\n",
        "\n",
        "estimate_mu_sigma_E(data)"
      ],
      "metadata": {
        "id": "Rr3CCRbEeUnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9968dcea-1b5f-43e9-d39f-db6fbb4e8e45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu 1: 11.219053\n",
            "sigma 1: 3.515402\n",
            "mu 2: 1.2190298\n",
            "sigma 2: 0.8788505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observaciones:\n",
        "\n",
        "Hemos intentado utilizar JAX para encontrar los parámetros de las muestras de dos gaussianas distintas, aprovechandonos de la capacidad de la libreria para calcular gradientes sobre un vector de parámetros. Sin embargo no parece que el segundo parámetro de mu i de sigma se aproxime correctamente, aunque el primer parámetro de estos sí se acerca a los valores deseados."
      ],
      "metadata": {
        "id": "AddjzKke7Mfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### f) Emplear la misma tasa de aprendizaje durante toda la optimización puede evitar que lleguemos realmente cerca del óptimo. Modificad el algoritmo que habéis implementado para que la tasa de aprendizaje vaya atenuándose con el número de iteraciones multiplicándola por un valor cercano a 1 $(0,9999, 0.999, 0,99, \\dots, 0.9)$. Repetid la optimización de vuestro mejor resultado en el apartado anterior con diferentes atenuaciones. ¿Ha afectado al resultado? ¿Ha afectado al número de iteraciones antes de converger?"
      ],
      "metadata": {
        "id": "Ceuk_Xg_NfWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_mu_sigma_dec(data):\n",
        "    epsilon = 1e-6\n",
        "    lr = 0.5\n",
        "    mu = 15.0\n",
        "    sigma = 10.0\n",
        "    grad_likelohood_mu = jit(grad(likelohood, argnums = 0)) \n",
        "    grad_likelohood_sigma = jit(grad(likelohood, argnums = 1))\n",
        "    grad_mu_mean = 0\n",
        "    grad_sigma_mean = 0\n",
        "    iterate = 10000\n",
        "    dec = np.linspace(1, 0.1, iterate)\n",
        "# dec = np.linspace(0.0002, 0.001, iterate)\n",
        "    # print(dec)\n",
        "    for i in range(iterate):\n",
        "        gradiente_mu = vmap(grad_likelohood_mu,in_axes=(None, None, 0))(mu, sigma, data)\n",
        "        gradiente_sigma = vmap(grad_likelohood_sigma,in_axes=(None, None, 0))(mu, sigma, data)\n",
        "        grad_mu_mean = jnp.mean(gradiente_mu)\n",
        "        grad_sigma_mean = jnp.mean(gradiente_sigma)\n",
        "        mu = mu - (lr * grad_mu_mean*dec[i])\n",
        "        sigma = sigma - (lr * grad_sigma_mean*dec[i])\n",
        "        if grad_mu_mean < epsilon and grad_sigma_mean < epsilon: \n",
        "            print(\"hemos llegado al minimo\")\n",
        "            print(i)\n",
        "            break\n",
        "    print(\"sigma: \" + str(sigma))\n",
        "    print(\"mu: \" + str(mu))\n",
        "\n",
        "\n",
        "print(\"data1\")\n",
        "estimate_mu_sigma_dec(data1)\n",
        "print(\"data2\")\n",
        "estimate_mu_sigma_dec(data2)\n",
        "print(\"data3\")\n",
        "estimate_mu_sigma_dec(data3)"
      ],
      "metadata": {
        "id": "-qNks12qWKCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e269be9-5f57-4e12-b922-971c19f36cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data1\n",
            "hemos llegado al minimo\n",
            "257\n",
            "sigma: 2.2816675\n",
            "mu: 10.273638\n",
            "data2\n",
            "hemos llegado al minimo\n",
            "349\n",
            "sigma: 2.961585\n",
            "mu: 9.919184\n",
            "data3\n",
            "hemos llegado al minimo\n",
            "354\n",
            "sigma: 3.0017204\n",
            "mu: 9.950227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observaciones:\n",
        "\n"
      ],
      "metadata": {
        "id": "hlHerMy2WLSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empleando distintas atenuaciones podemos ver que el número de iteraciones que tarda en converger es mayor pero tampoco de forma muy significativa (por ej. de 254 iteraciones a 257 en el primer conjunto de datos). Con atenuaciones más agresivas, se pueden conseguir resultados no deseables como que no podamos llegar a converger ya que el learning rate llegue a ser demasiado pequeño."
      ],
      "metadata": {
        "id": "LIXzZzOtg_3P"
      }
    }
  ]
}